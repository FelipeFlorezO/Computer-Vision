{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clasificación de imágenes\n",
    "Para iniciar, se llevará a cabo la tarea de clasificación de imágenes. Esta tarea se basa enteramente en el reconocimiento visual, y el objetivo es asignar a una imagen una única etiqueta sobre la clase a la que pertenece la imagen. Para ello, es necesario utilizar imágenes que contengan un único objeto para que así el algoritmo pueda asignar una etiqueta a la imagen. A continuación, encontrará las funciones necesarias para clasificar una imagen utilizando una red neuronal convolucional sencilla tomada de la librería OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from operator import itemgetter \n",
    "\n",
    "def cargarClasesImageNet():\n",
    "    with open(os.path.join(\"Datos\",\"clases_ImageNet.txt\"), \"r\") as f:\n",
    "        clases = f.readlines()\n",
    "    clases = [c.strip().split(\",\") for c in clases]\n",
    "    return clases\n",
    "\n",
    "def crearClasificador():\n",
    "    arquitectura = os.path.join(\"Datos\",\"DenseNet_121.prototxt.txt\")\n",
    "    pesos_preentrenados = os.path.join(\"Datos\",\"DenseNet_121.caffemodel\")\n",
    "    modelo = cv.dnn.readNetFromCaffe(arquitectura, pesos_preentrenados) \n",
    "    return modelo\n",
    "\n",
    "def cargarImagenClasificacion(ruta: str):\n",
    "    imagen = cv.imread(ruta)\n",
    "    entrada = cv.dnn.blobFromImage(imagen, 0.007843, (224, 224), (127.5, 127.5, 127.5))\n",
    "    return imagen, entrada\n",
    "\n",
    "def clasificar(ruta_imagen: str):\n",
    "    clases = cargarClasesImageNet()\n",
    "    modelo = crearClasificador()\n",
    "    imagen, entrada = cargarImagenClasificacion(ruta_imagen)\n",
    "    \n",
    "    modelo.setInput(entrada)\n",
    "    prediccion = modelo.forward().squeeze()\n",
    "    softmax = np.exp(prediccion)/np.sum(np.exp(prediccion))\n",
    "    top = np.flipud(np.argsort(softmax, axis=0)[-3:])\n",
    "    clases_top=itemgetter (*top)(clases)\n",
    "    confianzas_top = softmax[top]\n",
    "    return imagen, clases_top, confianzas_top\n",
    "\n",
    "def visualizar(imagen: np.array, clases: list, confianzas: list):\n",
    "    fig, ax = plt.subplots(1, 2, figsize=(10,5))\n",
    "    ax[0].set_title(\"Imagen de entrada\")\n",
    "    etiqueta=\"\"\n",
    "    for i in range(len(confianzas)):\n",
    "        etiqueta_i = \"{}) {} ({}). Confianza: {:.3f}\".format(i+1,clases[i][0],\", \".join(clases[i][1:]), confianzas[i]) if len(clases[i])>1 else '{}) {}. Confianza: {:.2f}'.format(i+1,clases[i][0],confianzas[i])\n",
    "        etiqueta += etiqueta_i + \"\\n\"\n",
    "    ax[0].imshow(imagen[:,:,::-1])\n",
    "    ax[0].axis(\"off\")\n",
    "    ax[1].set_title(\"Top 3: clases identificadas\")\n",
    "    ax[1].axis(\"off\")\n",
    "    ax[1].text(0,0.5, etiqueta, {'color': 'black', 'fontsize': 13})\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, vamos a visualizar las imágenes que vamos a clasificar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "import skimage.io as io\n",
    "import cv2 as cv\n",
    "plt.figure() \n",
    "plt.subplot(121) \n",
    "plt.imshow(cv.resize(io.imread(os.path.join(\"Datos\",\"gato.jpg\")), (800,800)))\n",
    "plt.axis(\"off\")\n",
    "plt.subplot(122) \n",
    "plt.imshow(cv.resize(io.imread(os.path.join(\"Datos\",\"perro.jpg\")), (800,800)))\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora se utilizarán las funciones definidas anteriormente para realizar la clasificación de cada imagen. Para ello, se debe indicar la ruta del archivo de imagen a la función clasificar() y luego se utiliza la función visualizar() para observar el resultado gráficamente. Se observaran las 3 predicciones con mayor confianza realiazada por el método de deep-learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ruta = os.path.join(\"Datos\",\"gato.jpg\")\n",
    "imagen, clase, confianza = clasificar(ruta)\n",
    "visualizar(imagen, clase, confianza)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = os.path.join(\"Datos\",\"perro.jpg\")\n",
    "imagen, clase, confianza = clasificar(ruta)\n",
    "visualizar(imagen, clase, confianza)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Su turno\n",
    "Lo invitamos a que experimente cargando una imagen de su preferencia y observe los resultados. Para esto, añada la imagen de su preferencia en la carpeta \"Datos\" y obtenga la visualización tal y como se hizo con las imágenes anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detección en video\n",
    "\n",
    "Ahora, se realizará la tarea de detección de objetos en videos. Esta tarea se basa tanto en el reconocimiento como en el agrupamiento visual, pues no solo se busca identificar varios objetos en una imagen, sino que se desea conocer su ubicación, la clase a la que pertenecen y las instancias que hay para ese tipo de objeto. En este caso, la detección se llevará a cabo en un video que simula el caso de los vehículos autónomos. Para esto, se realiza una detección en cada fotograma del video. A continuación, encontrará las funciones necesarias para realizar la tarea de detección utilizando una red neuronal convolucional de la librería OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from IPython.display import Video\n",
    "\n",
    "np.random.seed(20)\n",
    "\n",
    "def cargarClasesCOCO():\n",
    "    with open(os.path.join(\"Datos\", \"clases_COCO.txt\"),\"r\") as f:\n",
    "        clases = f.readlines()\n",
    "    clases.insert(0, \"__fondo__\")\n",
    "    colores = np.random.uniform(low=0, high=255, size=(len(clases),3))\n",
    "    return clases, colores\n",
    "\n",
    "def crearDetector():\n",
    "    arquitectura = os.path.join(\"Datos\", \"ssd_mobilenet_v3_large_coco_2020_01_14.pbtxt\")\n",
    "    pesos_preentrenados = os.path.join(\"Datos\", \"frozen_inference_graph.pb\")\n",
    "    modelo = cv.dnn_DetectionModel(pesos_preentrenados, arquitectura)\n",
    "    modelo.setInputSize(320,320)\n",
    "    modelo.setInputScale(1.0/127.5)\n",
    "    modelo.setInputMean((127.5,127.5,127.5))\n",
    "    modelo.setInputSwapRB(True)\n",
    "    return modelo\n",
    "\n",
    "def cargarVideoDeteccion(ruta: str):\n",
    "    video = cv.VideoCapture(ruta)\n",
    "    if (video.isOpened()==False):\n",
    "        print(\"Error al intentar abrir el archivo...\")\n",
    "    return video\n",
    "\n",
    "def detectar_Y_generar(ruta_video: str):\n",
    "    clases, colores = cargarClasesCOCO()\n",
    "    modelo = crearDetector()\n",
    "    video = cargarVideoDeteccion(ruta_video)\n",
    "    ancho = video.get(3)\n",
    "    alto = video.get(4)\n",
    "    out = cv.VideoWriter(os.path.join(\"output_video.mp4\"),cv.VideoWriter_fourcc(*'mpv4'), 12, (int(ancho),int(alto)))\n",
    "    \n",
    "    tiempo_maximo = time.time() + 60 # 60 segundos de cámara\n",
    "    (exito, imagen) = video.read()\n",
    "    print(\"Procesando video...\")\n",
    "    while exito and time.time()<tiempo_maximo:\n",
    "        clasesEtiquetasID, confianzas, cajas =modelo.detect(imagen, confThreshold=0.5)\n",
    "        cajas = list(cajas)\n",
    "        confianzas = list(np.array(confianzas).reshape(1,-1)[0])\n",
    "        confianzas = list(map(float, confianzas))\n",
    "        cajaIds = cv.dnn.NMSBoxes(cajas, confianzas, score_threshold=0.5, nms_threshold=0.2)\n",
    "        \n",
    "        for i in cajaIds:\n",
    "            caja = cajas[np.squeeze(i)]\n",
    "            confianza_clase = confianzas[np.squeeze(i)]\n",
    "            confianza_etiquetaID = np.squeeze(clasesEtiquetasID[np.squeeze(i)])\n",
    "            etiqueta_clase = clases[confianza_etiquetaID]\n",
    "            claseColor = [int(c) for c in colores[confianza_etiquetaID]]\n",
    "\n",
    "            texto_imprimir=\"{} ({:.2f}%)\".format(etiqueta_clase.strip(),confianza_clase*100)\n",
    "            x,y,w,h = caja\n",
    "\n",
    "            cv.rectangle(imagen, (x,y), (x+w,y+h), color= claseColor, thickness=2)\n",
    "            cv.putText(imagen, texto_imprimir, (x,y-10), cv.FONT_HERSHEY_PLAIN, 1, claseColor, 2)\n",
    "        out.write(imagen)\n",
    "        key = cv.waitKey(1) & 0xFF\n",
    "        if key== ord(\"q\"):\n",
    "            break\n",
    "        (exito, imagen) = video.read()\n",
    "    video.release()\n",
    "    out.release()\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación, vemos el video de prueba para realizar la detección:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "ruta_origen = os.path.join(\"Datos\",\"video.mp4\")\n",
    "Video(ruta_origen,width=1000, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, se utilizarán las funciones de manera similar a como se hizo en la parte de clasificación, pero esta vez para hacer detección en el video de prueba. Esto puede tardar algunos minutos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta = os.path.join(\"Datos\",\"video.mp4\")\n",
    "detectar_Y_generar(ruta)\n",
    "print(\"Video procesado exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora, veremos el resultado del video. Hemos reducido el número de frames por segundo en el video para que pueda ver claramente las etiquetas predichas por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Video\n",
    "ruta_generado = os.path.join(\"Datos\", \"output_video.mp4\")\n",
    "Video(ruta_generado,width=1000, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Su turno (Opcional)\n",
    "Si desea probar la detección de video sobre un video propio, utilice las funciones definidas en las celdas anteriores desde su compatdor. Para detectar sobre su video, pase la ruta de su video a la función detectar_Y_generar."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
